{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7f6e44-7a62-444b-99c3-d7bc0a1f1308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Pandas: 2.1.4\n",
      "Versão do LightGBM: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(f\"Versão do Pandas: {pd.__version__}\")\n",
    "\n",
    "import pyspark as pyspark\n",
    "print(f\"Versão do LightGBM: {pyspark.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e84f746-c222-459e-ba6d-24bae7e5182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e0e5c9-5385-4b07-a7bb-3ad3b3d8e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_parquet(\"../data/processed/final_data_numeric.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56020f-d59e-4e44-af03-b6e6448924e7",
   "metadata": {},
   "source": [
    "A divisão dos dados é feita com base nos account_ids, garantindo que as ofertas de um mesmo cliente não apareçam em conjuntos diferentes (treino, validação e teste). Isso simula um cenário real, onde o modelo seria treinado com um grupo de clientes e validado/testado com clientes novos, evitando o vazamento de dados (data leakage).\n",
    "\n",
    "Neste case, a única feature considerada é a offer_id, pois ela já representa uma combinação única das características de cada oferta. Essa abordagem simplifica uso das variáveis e permite avaliar o impacto de cada oferta como um todo, mas também limita a capacidade do modelo de generalizar para novas combinações de ofertas, já que o modelo não vê separadamente os atributos que compõem cada offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f447a6-eab0-4c2c-b524-e1594a328621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 10187, Validação: 2183, Teste: 2183\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Dividir account_ids em treino (60%), validação (20%), teste (20%) ---\n",
    "account_ids = final_dataset['account_id'].unique()\n",
    "\n",
    "# Primeiro split treino vs temp (40% para temp)\n",
    "train_ids, temp_ids = train_test_split(account_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Depois split temp em validação, teste (20%, 20%)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Treino: {len(train_ids)}, Validação: {len(val_ids)}, Teste: {len(test_ids)}')\n",
    "\n",
    "# --- 2. Criar datasets filtrados ---\n",
    "train_set = final_dataset[final_dataset['account_id'].isin(train_ids)].copy()\n",
    "val_set = final_dataset[final_dataset['account_id'].isin(val_ids)].copy()\n",
    "test_set = final_dataset[final_dataset['account_id'].isin(test_ids)].copy()\n",
    "\n",
    "# --- 3. Pré-processamento ---\n",
    "categorical_features = ['offer_id']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Treino\n",
    "X_train = train_set[categorical_features]\n",
    "y_train = train_set['has_offer_completed']\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Validação\n",
    "X_val = val_set[categorical_features]\n",
    "y_val = val_set['has_offer_completed']\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Teste\n",
    "X_test = test_set[categorical_features]\n",
    "y_test = test_set['has_offer_completed']\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# --- 4. Criar grupos para ranking ---\n",
    "group_train = train_set.groupby('account_id').size().to_numpy()\n",
    "group_val = val_set.groupby('account_id').size().to_numpy()\n",
    "group_test = test_set.groupby('account_id').size().to_numpy()\n",
    "\n",
    "# --- 5. Dataset LightGBM ---\n",
    "lgb_train = lgb.Dataset(X_train_proc, label=y_train, group=group_train)\n",
    "lgb_val = lgb.Dataset(X_val_proc, label=y_val, group=group_val)\n",
    "\n",
    "# --- 6. Treinar Ranker ---\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [3],\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_val],\n",
    "    num_boost_round=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb629e8e-1835-4f97-82bb-c1eacbd2642a",
   "metadata": {},
   "source": [
    "## Inferência e Geração de Recomendações Top-3\n",
    "\n",
    "Após o treinamento, usamos o modelo para prever scores para todas as ofertas do conjunto de teste. Para simular um cenário real de recomendação, criamos todas as combinações possíveis de clientes e ofertas. O modelo então atribui um score a cada combinação. Com base nesses scores, selecionamos as top-3 ofertas para cada cliente, que representam as recomendações mais promissoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edcaf1f-5441-4f79-8c49-3a64892e173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['score'] = model.predict(X_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a37414c-f87f-4445-9acb-4f45110de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obter a lista única de clientes e ofertas\n",
    "all_offers = final_dataset['offer_id'].unique().copy()\n",
    "test_clients = test_set['account_id'].unique().copy()\n",
    "\n",
    "# 2. Criar um DataFrame com todas as combinações cliente-oferta\n",
    "all_test_combinations = pd.DataFrame({\n",
    "    'account_id': np.repeat(test_clients, len(all_offers)),\n",
    "    'offer_id': np.tile(all_offers, len(test_clients))\n",
    "})\n",
    "\n",
    "# 3. Adicionar as ofertas de cada cliente\n",
    "# Mesclar as ofertas de `test_set` com as novas combinações. \n",
    "client_features = test_set[['account_id']].drop_duplicates()\n",
    "all_test_combinations = pd.merge(all_test_combinations, client_features, on='account_id', how='left')\n",
    "\n",
    "# 4. Pré-processar os novos dados\n",
    "X_all_combinations = all_test_combinations[categorical_features]\n",
    "X_all_combinations_proc = preprocessor.transform(X_all_combinations)\n",
    "\n",
    "# 5. Fazer a inferência (previsão dos scores)\n",
    "all_test_combinations['score_new'] = model.predict(X_all_combinations_proc)\n",
    "\n",
    "# 6. Selecionar as top-3 ofertas para cada cliente\n",
    "top3_offers_per_client = all_test_combinations.sort_values(\n",
    "    ['account_id', 'score_new'], ascending=[True, False]\n",
    ").groupby('account_id').head(3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aef62ce-4b17-4137-9606-91d646b5a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir as top-3 ofertas recomendadas com os dados reais de conversão do test_set\n",
    "# A junção deve ser feita pelas colunas 'account_id' e 'offer_id'.\n",
    "top3_with_conversion = pd.merge(\n",
    "    top3_offers_per_client,\n",
    "    test_set[['account_id', 'offer_id', 'has_offer_completed']],\n",
    "    on=['account_id', 'offer_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Retirar nan\n",
    "top3_with_conversion.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55e6df-bbdb-49f9-98a3-6618c52df7dd",
   "metadata": {},
   "source": [
    "## Avaliação das Métricas e Impacto de Negócio\n",
    "\n",
    "Para validar nossas recomendações, calculamos métricas de desempenho comparando-as com uma linha de base (baseline). A taxa de conversão baseline é a taxa de conversão geral das ofertas enviadas no grupo de teste. Em seguida, calculamos a taxa de conversão das nossas recomendações top-3, filtrando apenas as ofertas que existiam no conjunto de teste para uma comparação justa.\n",
    "\n",
    "A ideia principal é verificar o resultado obtido com o envio real das ofertas com o resultado hipotético se fossem enviadas apenas as Top-3 recomendações do modelo. Essa abordagem, no entanto, pode introduzir vié pois nem todas as ofertas previstas pelo modelo foram efetivamente enviadas.\n",
    "O ideal seria um teste A/B controlado, no qual um grupo recebe as ofertas segundo a regra de negócio atual e outro recebe as Top-3 ofertas do modelo.\n",
    "\n",
    "Os resultados indicam que as recomendações do modelo aumentam significativamente a taxa de conversão média (considerando apenas ofertas realmente enviadas), embora a taxa de sucesso (proporção de clientes que usaram pelo menos uma oferta) tenha caído levemente. Além disso, a média de ofertas enviadas no baseline foi de 3 por cliente, enquanto nas Top-3 o número caiu para apenas 1, já que nem todas as ofertas recomendadas estavam no conjunto enviado.\n",
    "\n",
    "Esse resultado é interessante, pois mesmo com menos ofertas enviadas, é possível obter conversão mais alta e sucesso próximo ao baseline.\n",
    "Considerando que o envio de ofertas envolve custos, aumentar a precisão enquanto reduz o volume enviado pode ser vantajoso estrategicamente.\n",
    "Se a empresa adotar essa lógica de priorização, o modelo de recomendação pode trazer contribuições relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc60d15e-3009-4401-b82a-e9d31a165376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de clientes únicos grupo teste: 2,183\n",
      "Qtd de ofertas enviadas grupo teste: 6,531\n",
      "Qtd média de ofertas por cliente grupo teste: 3\n",
      "Taxa de conversão baseline no GRUPO TESTE: 0.6288\n",
      "Taxa de sucesso baseline no GRUPO TESTE: 0.8058\n",
      "______________________\n",
      "Qtd de clientes com ofertas das Top-3 Recomendações: 1707\n",
      "Qtd de ofertas enviadas Top-3 Recomendações: 2,463\n",
      "Qtd média de ofertas por cliente Top-3 Recomendações: 1\n",
      "Taxa de Conversão Média das Top-3 Recomendações: 0.7231\n",
      "Taxa de sucesso das Top-3 Recomendações: 0.7727\n"
     ]
    }
   ],
   "source": [
    "# Taxa de conversão baseline NO GRUPO TESTE (sem ranking, taxa geral no teste)\n",
    "print(f\"Qtd de clientes únicos grupo teste: {len(test_set['account_id'].unique()):,.0f}\")\n",
    "print(f\"Qtd de ofertas enviadas grupo teste: {len(test_set['score']):,.0f}\")\n",
    "print(f\"Qtd média de ofertas por cliente grupo teste: {test_set[['has_offer_completed','account_id']].groupby('account_id').count()['has_offer_completed'].mean():,.0f}\")\n",
    "baseline_conversion_test = test_set['has_offer_completed'].mean()\n",
    "base_hit_rate = test_set[['has_offer_completed','account_id']].groupby('account_id').max()['has_offer_completed'].mean()\n",
    "print(f\"Taxa de conversão baseline no GRUPO TESTE: {baseline_conversion_test:.4f}\")\n",
    "print(f\"Taxa de sucesso baseline no GRUPO TESTE: {base_hit_rate:.4f}\")\n",
    "\n",
    "print(\"______________________\")\n",
    "conversion_rate = top3_with_conversion['has_offer_completed'].mean()\n",
    "print(f\"Qtd de clientes com ofertas das Top-3 Recomendações: {(top3_with_conversion['account_id'].nunique())}\")\n",
    "print(f\"Qtd de ofertas enviadas Top-3 Recomendações: {len(top3_with_conversion['has_offer_completed']):,.0f}\")\n",
    "print(f\"Qtd média de ofertas por cliente Top-3 Recomendações: {top3_with_conversion[['has_offer_completed','account_id']].groupby('account_id').count()['has_offer_completed'].mean():,.0f}\")\n",
    "print(f\"Taxa de Conversão Média das Top-3 Recomendações: {conversion_rate:.4f}\")\n",
    "# Agrupar por cliente e verificar se houve alguma conversão (valor máximo = 1)\n",
    "clients_with_hit = top3_with_conversion.groupby('account_id')['has_offer_completed'].max()\n",
    "# Contar quantos clientes tiveram pelo menos um acerto\n",
    "num_clients_with_hit = (clients_with_hit == 1).sum()\n",
    "# Calcular o Hit Rate\n",
    "total_clients = len(top3_with_conversion['account_id'].unique())\n",
    "hit_rate = num_clients_with_hit / total_clients\n",
    "print(f\"Taxa de sucesso das Top-3 Recomendações: {hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a51ed7-6235-4151-b29f-b4157ffb0cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
